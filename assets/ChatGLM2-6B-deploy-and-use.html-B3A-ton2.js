import{_ as i,c as r,e as p,w as e,f as l,g as c,o as h,h as o,b as a}from"./app-BfCDUtKQ.js";const d={},k=l(`<h1 id="" tabindex="-1"><a class="header-anchor" href="#"><span></span></a></h1><p>公司想训练自己的模型，服务于某个领域的，算是垂直领域的LLM专属模型，为产品赋能。</p><p>如果自己从头搞一套LLM，这个项目投入的资就太大了。所以站在巨人的肩膀上，选择了<code>ChatGLM-6B</code></p><p>作为运维岗，或许我不需要深入了解这里面的算法，但需要简单的搞清楚，它的研发和部署逻辑。所以部署了下，做个记录</p><h2 id="chatglm-6b" tabindex="-1"><a class="header-anchor" href="#chatglm-6b"><span>ChatGLM-6B</span></a></h2><p><a href="https://github.com/thudm/chatglm2-6b#%E4%BB%8B%E7%BB%8D" target="_blank" rel="noopener noreferrer">模型的介绍，跳转官网查看</a></p><p>相关部署，里面也都有</p><div class="hint-container info"><p class="hint-container-title">声明</p><p>此文档，仅用于记录自己在MacOS下的部署，如有需要， 建议看官方文档为主。所有安装部署过程，官方README内都有</p></div><h2 id="环境的安装" tabindex="-1"><a class="header-anchor" href="#环境的安装"><span>环境的安装</span></a></h2><p>下载项目</p><div class="language-shell" data-ext="shell" data-title="shell"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">git</span><span style="color:#98C379;--shiki-dark:#98C379;"> clone</span><span style="color:#98C379;--shiki-dark:#98C379;"> https://github.com/THUDM/ChatGLM-6B</span></span></code></pre></div><p>环境初始化</p><p>创建隔离环境</p><div class="language-shell" data-ext="shell" data-title="shell"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">mkdir</span><span style="color:#98C379;--shiki-dark:#98C379;"> ChatGLM-6B</span></span>
<span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">virtualenv</span><span style="color:#D19A66;--shiki-dark:#D19A66;"> -p</span><span style="color:#98C379;--shiki-dark:#98C379;"> python3.9.16</span><span style="color:#98C379;--shiki-dark:#98C379;">  venv</span></span></code></pre></div><p>安装依赖</p><div class="language-shell" data-ext="shell" data-title="shell"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#56B6C2;--shiki-dark:#56B6C2;">cd</span><span style="color:#98C379;--shiki-dark:#98C379;"> ChatGLM-6B</span></span>
<span class="line"><span style="color:#61AFEF;--shiki-dark:#61AFEF;">pip</span><span style="color:#98C379;--shiki-dark:#98C379;"> install</span><span style="color:#D19A66;--shiki-dark:#D19A66;"> -r</span><span style="color:#98C379;--shiki-dark:#98C379;"> requirements.txt</span></span></code></pre></div><h2 id="模型下载" tabindex="-1"><a class="header-anchor" href="#模型下载"><span>模型下载</span></a></h2><p>将下载后的模型存放在某个目录下，使用时，指定此目录即可</p>`,18),B=a("p",null,[a("a",{href:"https://cloud.tsinghua.edu.cn/d/674208019e314311ab5c/",target:"_blank",rel:"noopener noreferrer"},"清华网盘")],-1),b=a("div",{class:"language-bash","data-ext":"bash","data-title":"bash"},[a("pre",{class:"shiki shiki-themes one-dark-pro one-dark-pro vp-code",style:{"background-color":"#282c34","--shiki-dark-bg":"#282c34",color:"#abb2bf","--shiki-dark":"#abb2bf"},tabindex:"0"},[a("code",null,[a("span",{class:"line"},[a("span",{style:{color:"#61AFEF","--shiki-dark":"#61AFEF"}},"git"),a("span",{style:{color:"#98C379","--shiki-dark":"#98C379"}}," clone"),a("span",{style:{color:"#98C379","--shiki-dark":"#98C379"}}," https://huggingface.co/THUDM/chatglm2-6b")])])])],-1),g=l(`<h2 id="服务启动" tabindex="-1"><a class="header-anchor" href="#服务启动"><span>服务启动</span></a></h2><h3 id="macos" tabindex="-1"><a class="header-anchor" href="#macos"><span>macos</span></a></h3><p><a href="https://developer.apple.com/metal/pytorch/" target="_blank" rel="noopener noreferrer">安装 PyTorch-Nightly</a></p><blockquote><p>pip3 install --pre torch torchvision torchaudio --extra-index-url <a href="https://download.pytorch.org/whl/nightly/cpu" target="_blank" rel="noopener noreferrer">https://download.pytorch.org/whl/nightly/cpu</a></p></blockquote><p>修改启动文件</p><div class="language-python" data-ext="python" data-title="python"><pre class="shiki shiki-themes one-dark-pro one-dark-pro vp-code" style="background-color:#282c34;--shiki-dark-bg:#282c34;color:#abb2bf;--shiki-dark:#abb2bf;" tabindex="0"><code><span class="line"><span style="color:#D19A66;--shiki-dark:#D19A66;">MODEL_PATH</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;"> =</span><span style="color:#98C379;--shiki-dark:#98C379;"> &quot;/xxxxx/offline-model/chatglm2-6b&quot;</span></span>
<span class="line"><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">model </span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;"> AutoModel.</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">from_pretrained</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#D19A66;--shiki-dark:#D19A66;">MODEL_PATH</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">, </span><span style="color:#E06C75;font-style:italic;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">trust_remote_code</span><span style="color:#56B6C2;--shiki-dark:#56B6C2;">=</span><span style="color:#D19A66;--shiki-dark:#D19A66;">True</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">).</span><span style="color:#61AFEF;--shiki-dark:#61AFEF;">to</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">(</span><span style="color:#98C379;--shiki-dark:#98C379;">&#39;mps&#39;</span><span style="color:#ABB2BF;--shiki-dark:#ABB2BF;">)</span></span></code></pre></div><p><code>python web_demo.py</code> 启动服务, 其他启动方式均需要调整与加载的模型</p><h2 id="模型微调" tabindex="-1"><a class="header-anchor" href="#模型微调"><span>模型微调</span></a></h2><p><a href="https://github.com/THUDM/ChatGLM2-6B/tree/main/ptuning" target="_blank" rel="noopener noreferrer">P-tuining</a></p><p>目前看来，需要注意的有:</p><ol><li>ChatGLM2-6B离线模型的管理和维护</li><li>模型微调-数据集的管理和维护</li><li>模型推理-机器资源的运维</li><li>模型推理-训练后模型管理与维护</li></ol><p>借此机会，之后可能需要了解下 <code>MLOps</code></p>`,12);function m(y,u){const n=c("Tabs");return h(),r("div",null,[k,p(n,{id:"50",data:[{id:"网盘"},{id:"huggingface"}]},{title0:e(({value:s,isActive:t})=>[o("网盘")]),title1:e(({value:s,isActive:t})=>[o("huggingface")]),tab0:e(({value:s,isActive:t})=>[B]),tab1:e(({value:s,isActive:t})=>[b]),_:1}),g])}const f=i(d,[["render",m],["__file","ChatGLM2-6B-deploy-and-use.html.vue"]]),L=JSON.parse(`{"path":"/coder/ops/ChatGLM2-6B-deploy-and-use.html","title":"ChatGLM2-6B","lang":"zh-CN","frontmatter":{"title":"ChatGLM2-6B","order":99,"index":true,"article":false,"description":"公司想训练自己的模型，服务于某个领域的，算是垂直领域的LLM专属模型，为产品赋能。 如果自己从头搞一套LLM，这个项目投入的资就太大了。所以站在巨人的肩膀上，选择了ChatGLM-6B 作为运维岗，或许我不需要深入了解这里面的算法，但需要简单的搞清楚，它的研发和部署逻辑。所以部署了下，做个记录 ChatGLM-6B 模型的介绍，跳转官网查看 相关部署，...","head":[["meta",{"property":"og:url","content":"https://docs.lizili.online/coder/ops/ChatGLM2-6B-deploy-and-use.html"}],["meta",{"property":"og:site_name","content":"lzz's Blog"}],["meta",{"property":"og:title","content":"ChatGLM2-6B"}],["meta",{"property":"og:description","content":"公司想训练自己的模型，服务于某个领域的，算是垂直领域的LLM专属模型，为产品赋能。 如果自己从头搞一套LLM，这个项目投入的资就太大了。所以站在巨人的肩膀上，选择了ChatGLM-6B 作为运维岗，或许我不需要深入了解这里面的算法，但需要简单的搞清楚，它的研发和部署逻辑。所以部署了下，做个记录 ChatGLM-6B 模型的介绍，跳转官网查看 相关部署，..."}],["meta",{"property":"og:type","content":"website"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-11-10T04:16:31.000Z"}],["meta",{"property":"article:author","content":"z"}],["meta",{"property":"article:modified_time","content":"2024-11-10T04:16:31.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"WebPage\\",\\"name\\":\\"ChatGLM2-6B\\",\\"description\\":\\"公司想训练自己的模型，服务于某个领域的，算是垂直领域的LLM专属模型，为产品赋能。 如果自己从头搞一套LLM，这个项目投入的资就太大了。所以站在巨人的肩膀上，选择了ChatGLM-6B 作为运维岗，或许我不需要深入了解这里面的算法，但需要简单的搞清楚，它的研发和部署逻辑。所以部署了下，做个记录 ChatGLM-6B 模型的介绍，跳转官网查看 相关部署，...\\"}"]]},"headers":[{"level":2,"title":"ChatGLM-6B","slug":"chatglm-6b","link":"#chatglm-6b","children":[]},{"level":2,"title":"环境的安装","slug":"环境的安装","link":"#环境的安装","children":[]},{"level":2,"title":"模型下载","slug":"模型下载","link":"#模型下载","children":[]},{"level":2,"title":"服务启动","slug":"服务启动","link":"#服务启动","children":[{"level":3,"title":"macos","slug":"macos","link":"#macos","children":[]}]},{"level":2,"title":"模型微调","slug":"模型微调","link":"#模型微调","children":[]}],"git":{"createdTime":1689928489000,"updatedTime":1731212191000,"contributors":[{"name":"lizili","email":"cn.zili.lee@outlook.com","commits":1}]},"readingTime":{"minutes":1.5,"words":450},"filePathRelative":"coder/ops/ChatGLM2-6B-deploy-and-use.md","localizedDate":"2023年7月21日","excerpt":"\\n<p>公司想训练自己的模型，服务于某个领域的，算是垂直领域的LLM专属模型，为产品赋能。</p>\\n<p>如果自己从头搞一套LLM，这个项目投入的资就太大了。所以站在巨人的肩膀上，选择了<code>ChatGLM-6B</code></p>\\n<p>作为运维岗，或许我不需要深入了解这里面的算法，但需要简单的搞清楚，它的研发和部署逻辑。所以部署了下，做个记录</p>\\n<h2>ChatGLM-6B</h2>\\n<p><a href=\\"https://github.com/thudm/chatglm2-6b#%E4%BB%8B%E7%BB%8D\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">模型的介绍，跳转官网查看</a></p>","autoDesc":true}`);export{f as comp,L as data};
